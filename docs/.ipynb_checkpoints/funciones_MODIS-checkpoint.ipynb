{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Autor:_    __Jesús Casado__ <br> _Revisión:_ __22/11/2019__ <br>\n",
    "\n",
    "__Introducción__<br>\n",
    "Código con funciones para la descarga y tratamiento de datos MODIS.\n",
    "\n",
    "Los datos MODIS se descargan del [servidor USGS](https://e4ftl01.cr.usgs.gov/). En dicho enlace se pueden ver las misiones, productos y fechas disponibles. Para poder descargar datos del servidor, es necesario estar registrado en https://urs.earthdata.nasa.gov/.\n",
    "\n",
    "En el tratamiento de datos se incluye una función para extraer los datos de un producto para la variable, fechas y cuenca de interés.\n",
    "\n",
    "__Cosas que arreglar__ <br>\n",
    "\n",
    "***\n",
    "__Índice__<br>\n",
    "__[Descarga de datos MODIS](#Descarga-de-datos-MODIS)__<br>\n",
    "\n",
    "__[Tratamiento de datos MODIS](#Tratamiento-de-datos-MODIS)__<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "from http.cookiejar import CookieJar\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline\n",
    "from netCDF4 import Dataset\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import os\n",
    "\n",
    "from pyproj import Proj, transform#, CRS\n",
    "os.environ['PROJ_LIB'] = r'C:\\Anaconda3\\pkgs\\proj4-4.9.3-vc14_5\\Library\\share'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: 'F:/Codigo/Python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-798e50c221c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F:/Codigo/Python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'run'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read_write.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: 'F:/Codigo/Python'"
     ]
    }
   ],
   "source": [
    "os.chdir('F:/Codigo/Python')\n",
    "%run read_write.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar las funciones de `read_write.py` desde un repositorio de GitHub debería hacerse algo parecido a lo siguiente:\n",
    "```Python\n",
    "import requests\n",
    "def githubimport(user, repo, module):\n",
    "   d = {}\n",
    "   url = 'https://raw.githubusercontent.com/{}/{}/master/{}.py'.format(user, repo, module)\n",
    "   r = requests.get(url).text\n",
    "   exec(r, d)\n",
    "   return d\n",
    "\n",
    "qoperator = githubimport('biryani', 'Quacpy', 'qoperator')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descarga de datos MODIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EarthdataLogin(username, password, url='https://urs.earthdata.nasa.gov'):\n",
    "    \"\"\"Entra en la cuenta de usuario de Earthdata, con lo que se obtiene permiso para descargar .hdf, y crea un contenedor de las 'cookies' en la sesión.\n",
    "    \n",
    "    Modificado de https://wiki.earthdata.nasa.gov/display/EL/How+To+Access+Data+With+Python\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    username: string. Nombre de usuario en Earthdata\n",
    "    password: string. Contraseña en Earthdata\n",
    "    url:     string. URL del servidor de datos; por defecto 'https://e4ftl01.cr.usgs.gov/'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a password manager to deal with the 401 reponse that is returned from Earthdata Login\n",
    "    password_manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    "    \n",
    "    # Create a cookie jar for storing cookies. This is used to store and return\n",
    "    # the session cookie given to use by the data server (otherwise it will just\n",
    "    # keep sending us back to Earthdata Login to authenticate).  Ideally, we\n",
    "    # should use a file based cookie jar to preserve cookies between runs. This\n",
    "    # will make it much more efficient.\n",
    "    cookie_jar = CookieJar()\n",
    "    \n",
    "    # Install all the handlers.\n",
    "    opener = urllib.request.build_opener(urllib.request.HTTPBasicAuthHandler(password_manager),\n",
    "                                         #urllib.request.HTTPHandler(debuglevel=1),    # Uncomment these two lines to see\n",
    "                                         #urllib.request.HTTPSHandler(debuglevel=1),   # details of the requests/responses\n",
    "                                         urllib.request.HTTPCookieProcessor(cookie_jar))\n",
    "    urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dir(url, ext='/'):\n",
    "    \"\"\"Extrae los directorios existentes en una url.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    ulr:     string. Dirección url\n",
    "    ext:     string. Caracter a buscar al final de cada nodo de la url para idenficarlo como un nuevo directorio\"\"\"\n",
    "    \n",
    "    # extrae el texto de la url\n",
    "    page = requests.get(url).text\n",
    "    # traduce el texto\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    # extrae las líneas del texto terminadas en 'ext'\n",
    "    list_dir = [url + node.get('href') for node in soup.find_all('a') if node.get('href').endswith(ext)]\n",
    "    \n",
    "    return list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descarga_MODIS(username, password, path, product, start=None, end=None, tiles=None,\n",
    "                   url='https://e4ftl01.cr.usgs.gov/', format='hdf'):\n",
    "    \"\"\"Descarga los archivos del producto MODIS de interés en las fechas, hojas y formato indicados.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    username: string. Nombre de usuario en Earthdata\n",
    "    password: string. Contraseña en Earthdata\n",
    "    path:    string. Carpeta donde guardar los datos descargados.\n",
    "    product: string. Producto MODIS. P.ej.: 'MOD16A2.006', 'MYD16A2.006'\n",
    "    start:   string. Fecha a partir de la que descargar datos. Formato 'YYYY-MM-DD'\n",
    "    end:     string. Fecha hasta la que descargar datos. Formato 'YYYY-MM-DD'\n",
    "    tiles:   list of strings. Hojas MODIS a descargar. Formato 'h00v00'\n",
    "    url:     string. URL del servidor de datos; por defecto 'https://e4ftl01.cr.usgs.gov/'\n",
    "    format:  string. Tipo de archivo a descargar: 'hdf', 'jpg', 'xml'\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    Se guardan en la carpeta 'path/product' los archivos (hdf, jpg o xml) para la selección indicada.\"\"\"\n",
    "    \n",
    "    # entrar en Earth data con el usuario\n",
    "    EarthdataLogin('casadoj', 'Chomolungma1619', url=url)\n",
    "    \n",
    "    # definir carpeta donde guardar los datos\n",
    "    exportpath = path + '/' + product.split('.')[0] + '/'\n",
    "    if os.path.isdir(exportpath) == False:\n",
    "        os.mkdir(exportpath)\n",
    "    os.chdir(exportpath)\n",
    "    lsdir = os.listdir()\n",
    "    \n",
    "    # url de cada una de las misiones\n",
    "    url_missions = extract_dir(url)\n",
    "    # diccionario con las missiones y sus productos\n",
    "    mission_products = {}\n",
    "    for fd1 in url_missions:\n",
    "        mission = fd1.split('/')[-2]\n",
    "        url_products = extract_dir(fd1)\n",
    "        products = [fd2.split('/')[-2] for fd2 in url_products if fd2.split('/')[-2] != '']\n",
    "        mission_products[mission] = products\n",
    "\n",
    "    # encontrar missión del producto de interés y url del producto\n",
    "    for fd, mission in zip(url_missions, mission_products.keys()):\n",
    "        if product in mission_products[mission]:\n",
    "            urlproduct = fd + product + '/'\n",
    "            break\n",
    "    \n",
    "    # convertir en datetime.date las fechas de inicio y fin de la búsqueda           \n",
    "    if start != None:\n",
    "        start = datetime.strptime(start, '%Y-%m-%d').date()\n",
    "    else:\n",
    "        start = datetime(1950, 1, 1).date()\n",
    "    if end != None:        \n",
    "        end = datetime.strptime(end, '%Y-%m-%d').date()\n",
    "    else:\n",
    "        end = datetime.now().date()\n",
    "        \n",
    "    # seleccionar fechas dentro del periodo de interés\n",
    "    urldates = []\n",
    "    for fd in extract_dir(urlproduct)[1:]:\n",
    "        date = datetime.strptime(fd.split('/')[-2], '%Y.%m.%d').date()\n",
    "        if (start <= date) & (end >= date):\n",
    "            urldates.append(fd)\n",
    "            \n",
    "    for di, urldate in enumerate(urldates):\n",
    "        # seleccionar archivos correspondientes a las hojas de interés\n",
    "        urlfiles = extract_dir(urldate, ext='.' + format)\n",
    "        if tiles == None:\n",
    "            files = [file.split('/')[-1] for file in urlfiles]\n",
    "        else:\n",
    "            files = [file.split('/')[-1] for file in urlfiles if any(tile in file for tile in tiles)]\n",
    "\n",
    "        # descargar archivos\n",
    "        for fi, file in enumerate(files):\n",
    "            print('Fecha {0:>4} de {1:>4}; archivo {2:>3} de {3:>3}'.format(di + 1, len(urldates),\n",
    "                                                                            fi + 1, len(files)),\n",
    "                  end='\\r')\n",
    "            if file in lsdir:\n",
    "                continue\n",
    "            else:\n",
    "                urllib.request.urlretrieve(urldate + file, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de datos MODIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ascii2df(pathfile):\n",
    "    \"\"\"Importar ASCII en forma de DataFrame\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    path:    string. Ruta incluyendo nombre del archivo y extensión\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    asc:    data frame. Con las coordenadas en índices y columnas\n",
    "    \"\"\"\n",
    "    \n",
    "    # mdt de la cuenca\n",
    "    read_ascii(pathfile)\n",
    "    asc = read_ascii.data\n",
    "    ncols, nrows, Xo, Yo, cellsize, nanvalue = read_ascii.attributes\n",
    "    \n",
    "    # coordenadas X del centro de las celdas\n",
    "    Xf = Xo + ncols * cellsize\n",
    "    Xo += cellsize / 2\n",
    "    Xf += cellsize / 2\n",
    "    XXasc = np.arange(Xo, Xf, cellsize).astype('int')\n",
    "    \n",
    "    # coordenadas Y del centro de las celdas\n",
    "    Yf = Yo + nrows * cellsize\n",
    "    Yo += cellsize / 2\n",
    "    Yf += cellsize / 2\n",
    "    YYasc = np.arange(Yo, Yf, cellsize).astype('int')[::-1]\n",
    "    \n",
    "    # convertir 'asc' en un DataFrame\n",
    "    asc = pd.DataFrame(data=asc, index=YYasc, columns=XXasc)\n",
    "    asc.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    return asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MODIS_extract(path, product, var, atributes, factor=None, dateslim=None, clip=None,\n",
    "                  coordsClip='epsg:25830', verbose=True):\n",
    "    \"\"\"Extrae los datos de MODIS para un producto, variable y fechas dadas, transforma las coordenadas y recorta a la zona de estudio.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    path:       string. Ruta donde se encuentran los datos de MODIS (ha de haber una subcarpeta para cada producto)\n",
    "    product:    string. Nombre del producto MODIS, p.ej. MOD16A2\n",
    "    var:        string. Variable de interés dentro de los archivos 'hdf'\n",
    "    atributes:  list. [ncols, nrows, Xtopleft, Ytopleft, Xbottomright, Ybottomright]\n",
    "    factor:     float. Factor con el que multiplicar los datos para obtener su valore real (comprobar en la página de MODIS para el producto y variable de interés)\n",
    "    dateslim:   list. Fechas de inicio y fin del periodo de estudio en formato YYYY-MM-DD. Si es 'None', se extraen los datos para todas las fechas disponibles\n",
    "    clip:       string. Ruta y nombre del archivo ASCII que se utilizará como máscara para recortar los datos. Si es 'None', se extraen todos los datos\n",
    "    coordsClip: string. Código EPSG o Proj del sistema de coordenadas al que se quieren transformar los datos. Si en 'None', se mantiene el sistema de coordenadas sinusoidal de MODIS\n",
    "    verbose:    boolean. Si se quiere mostrar en pantalla el desarrollo de la función\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    Como métodos:\n",
    "        data:    array (2D ó 3D). Mapas de la variable de interés. 3D si hay más de un archivo (más de una fecha)\n",
    "        Xcoords: array (2D). Coordenadas X de cada celda de los mapas de 'data'\n",
    "        Ycoords: array (2D). Coordenadas Y de cada celda de los mapas de 'data'\n",
    "        dates:   list. Fechas a las que corresponde cada uno de los maapas de 'data'\n",
    "    \"\"\"\n",
    "    \n",
    "    # SELECCIÓN DE ARCHIVOS\n",
    "    # ---------------------\n",
    "    if dateslim is not None:\n",
    "        # convertir fechas límite en datetime.date\n",
    "        start = datetime.strptime(dateslim[0], '%Y-%m-%d').date()\n",
    "        end = datetime.strptime(dateslim[1], '%Y-%m-%d').date()\n",
    "\n",
    "    # seleccionar archivos del producto y fechas dadas\n",
    "    path = path + product + '/'\n",
    "    os.chdir(path)\n",
    "    dates, files = [], []\n",
    "    for file in [file for file in os.listdir() if product in file]:\n",
    "        year = file.split('.')[1][1:5]\n",
    "        doy = file.split('.')[1][5:]\n",
    "        date = datetime.strptime(' '.join([year, doy]), '%Y %j').date()\n",
    "        if dateslim is not None:\n",
    "            if (date>= start) & (date <= end):\n",
    "                dates.append(date)\n",
    "                files.append(file)\n",
    "        else:\n",
    "            dates.append(date)\n",
    "            files.append(file)\n",
    "\n",
    "    # ATRIBUTOS MODIS\n",
    "    # ---------------\n",
    "    ncols, nrows, Xo, Yf, Xf, Yo = atributes\n",
    "\n",
    "    # coordenadas x de las celdas\n",
    "    Xmodis = np.linspace(Xo, Xf, ncols)\n",
    "    # coordenadas y de las celdas\n",
    "    Ymodis = np.linspace(Yf, Yo, nrows)\n",
    "    # matrices 2D con las coordenadas X e Y de cada celda\n",
    "    XXmodis, YYmodis = np.meshgrid(Xmodis, Ymodis)\n",
    "\n",
    "    if coordsClip is not None:\n",
    "        # definir sistemas de referencia de coordenadas\n",
    "        ProjOut = Proj(init=coordsClip)\n",
    "        # https://spatialreference.org/ref/sr-org/modis-sinusoidal/\n",
    "        SINUSOIDAL = Proj(projparams='PROJCS[\"Sinusoidal\",GEOGCS[\"GCS_Undefined\",DATUM[\"D_Undefined\",SPHEROID[\"User_Defined_Spheroid\",6371007.181,0.0]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.017453292519943295]],PROJECTION[\"Sinusoidal\"],PARAMETER[\"False_Easting\",0.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",0.0],UNIT[\"Meter\",1.0]]')\n",
    "\n",
    "        # transformar coordenadas\n",
    "        Xmodis, Ymodis = transform(SINUSOIDAL, ProjOut, XXmodis.flatten(), YYmodis.flatten())\n",
    "        XXmodis, YYmodis = Xmodis.reshape((nrows, ncols)), Ymodis.reshape((nrows, ncols))\n",
    "\n",
    "    # CREAR MÁSCARAS\n",
    "    # --------------\n",
    "    if clip is not None:\n",
    "        # cargar ascii\n",
    "        clipdf = ascii2df(clip)\n",
    "        # extensión del ascii\n",
    "        Xbo, Xbf = clipdf.columns.min(), clipdf.columns.max()\n",
    "        Ybo, Ybf = clipdf.index.min(), clipdf.index.max()\n",
    "\n",
    "        # mapa auxiliar del tamaño de los hdf\n",
    "        aux = np.ones((nrows, ncols))\n",
    "        # convertir en NaN celdas fuera del rectángulo de extensión de la cuenca\n",
    "        maskExtent = (XXmodis >= Xbo) & (XXmodis <= Xbf) & (YYmodis >= Ybo) & (YYmodis <= Ybf)\n",
    "        aux[~maskExtent] = np.nan\n",
    "        # filas (maskR) y columnas (masC) en la extensión de la cuenca\n",
    "        maskRows = ~np.all(np.isnan(aux), axis=1)\n",
    "        maskCols = ~np.all(np.isnan(aux), axis=0)\n",
    "\n",
    "        # recortar aux\n",
    "        aux = aux[maskRows, :][:, maskCols]\n",
    "        # extraer coordenadas en el rectángulo de extensión de la cuenca\n",
    "        XXb, YYb = XXmodis[maskRows, :][:, maskCols], YYmodis[maskRows, :][:, maskCols]\n",
    "\n",
    "        # convertir en NaN celdas fuera de la cuenca\n",
    "        for c, (y, x) in enumerate(zip(YYb.flatten(), XXb.flatten())):\n",
    "            ibasin, jbasin = np.argmin(abs(y - clipdf.index)), np.argmin(abs(x - clipdf.columns))\n",
    "            if np.isnan(clipdf.iloc[ibasin, jbasin]):\n",
    "                imodis, jmodis = int(c / XXb.shape[1]), c % XXb.shape[1]\n",
    "                aux[imodis, jmodis] = np.nan\n",
    "                maskClip = np.isnan(aux)\n",
    "        if verbose == True:\n",
    "            print('nº filas: {0:>3}\\tnº columnas: {1:>3}'.format(aux.shape[0], aux.shape[1]))\n",
    "\n",
    "    # IMPORTAR DATOS\n",
    "    # --------------\n",
    "    for i, file in enumerate(files):\n",
    "        if verbose is True:\n",
    "            print('Archivo {0:>3} de {1:>3}'.format(i + 1, len(files)), end='\\r')\n",
    "        # cargar archivo 'hdf'\n",
    "        f = Dataset(path + file, format='hdf4')\n",
    "        # extraer datos de la variable\n",
    "        if clip is not None:  \n",
    "            tmp = f[var][maskRows, :][:, maskCols]\n",
    "            tmp[tmp.mask] = np.nan\n",
    "            tmp[maskClip] = np.nan\n",
    "        else:\n",
    "            tmp = f[var][:]\n",
    "            tmp[tmp.mask] = np.nan\n",
    "        # guardar datos en un array\n",
    "        if i == 0:\n",
    "            data = tmp.data\n",
    "        else:\n",
    "            data = np.dstack((data, tmp.data))\n",
    "        del tmp\n",
    "        f.close()\n",
    "    if factor is not None:\n",
    "        data *= factor\n",
    "    \n",
    "    # GUARDAR RESULTADOS\n",
    "    # ------------------\n",
    "    MODIS_extract.data = data\n",
    "    MODIS_extract.dates = dates\n",
    "    if clip is not None:\n",
    "        MODIS_extract.Xcoords = XXb\n",
    "        MODIS_extract.Ycoords = YYb\n",
    "    else:\n",
    "        MODIS_extract.Xcoords = XXmodis\n",
    "        MODIS_extract.Ycoords = YYmodis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMODISseries(data, var, timevar, r, ymin=None, ylabel=None, lw=.25, alpha=.1):\n",
    "    \"\"\"Figura con un gráfico de línea para Terra y otro para Aqua con la serie temporal de data.\n",
    "    \n",
    "    Entradas:\n",
    "    ---------\n",
    "    data:    dict. Contiene los datos de 'Terra' y 'Aqua' en la variable 'var' para las fechas en la variable 'timevar'\n",
    "    var:     string. Nombre de la variable de interés dentro de 'data'\n",
    "    timevar: string. Nombre de la variable deentro de 'data' que contiene las fechas\n",
    "    ymin:    boolean. Si se quiere calcular el mínimo del eje Y (True), o se fija en 0 (False)\n",
    "    r:       string. Redondeo\n",
    "    ylabel:  string. Etiqueta del eje y\n",
    "    lw:      float. Grosor de línea\n",
    "    alpha:   float. Transparencia\n",
    "    \"\"\"\n",
    "    \n",
    "    # mostrar la serie 8-diaria para cada celda y la media de la cuenca\n",
    "    fig, axes = plt.subplots(nrows=2, figsize=(15, 7), sharex=True)\n",
    "\n",
    "    xlim = [min(min(data['Terra'][timevar]), min(data['Aqua'][timevar])),\n",
    "            max(max(data['Terra'][timevar]), max(data['Aqua'][timevar]))]\n",
    "    if ymin == True:\n",
    "        ymin = np.floor(min([np.nanmin(data[sat][var]) for sat in data.keys()]) / r) * r\n",
    "    else:\n",
    "        ymin = 0\n",
    "    ymax = np.ceil(max([np.nanmax(data[sat][var]) for sat in data.keys()]) / r) * r\n",
    "    colors = [['yellowgreen', 'darkolivegreen'], ['lightsteelblue', 'steelblue']]\n",
    "\n",
    "    for c, (ax, sat) in enumerate(zip(axes, ['Terra', 'Aqua'])):\n",
    "        timex, datax = data[sat][timevar], data[sat][var]\n",
    "        for i in range(datax.shape[1]):\n",
    "            for j in range(datax.shape[2]):\n",
    "                if np.isnan(datax[:,i,j]).sum() == datax.shape[0]: # celda vacía\n",
    "                    continue\n",
    "                else:\n",
    "                    # serie de una celda\n",
    "                    ax.plot(timex, datax[:, i,j], lw=lw, c=colors[c][0], alpha=alpha)\n",
    "        # serie media areal\n",
    "        ax.plot(timex, np.nanmean(datax, axis=(1, 2)), c=colors[c][1], lw=4*lw)\n",
    "        # configuración\n",
    "        ax.tick_params(labelsize=11)\n",
    "        ax.set(xlim=xlim, ylim=(ymin, ymax))\n",
    "        ax.set_ylabel(ylabel, fontsize=13)\n",
    "        ax.set_title(sat, fontsize=13, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
